{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvimento de conversao arquivo h01 para netcdf\n",
    "Este é um esqueleto para processamento dos arquivos csv/txt das plataformas, e conversão para netcdf, assim como preenchimento dos dados de informações (metadados). Os passos são os seguintes:\n",
    "1. Abre arquivo JSON onde informações de configuração, da plataforma e dos arquivo netcdf estão armazenadas. Isso é necessário para flexibilizar o código e permitir reutilizacao do código. Isso é vantajoso quando várias estações com mesmo modelo de arquivo de saída são utilizadas.\n",
    "2. Abertura do arquivo de imagem e conversão para base64. O arquivo netcdf não tem um tipo de variável adequado para armazenamento direto de arquivos binários. Ainda não esta fechado a melhor forma de armazenar esse tipo de dado dentro do netcdf, mas acho que converter o arquivo para baser64 (texto, muito utilizado em navegadores de internet) é um método razoavel. A vantagem dessa conversão é permitr armazenar os arquivos como texto simples, e fácil de recuperar. Esse formato ainda pode ser revisto.\n",
    "3. Leitura do arquivo de dados, e varredura para alguns termos para confirmar que arquivo é da estação definida. Leitura das medidas em uma tabela Pandas\n",
    "4. Criação do arquivo netcdf\n",
    "5. Geração de metadados\n",
    "6. Inserção dos dados no arquivo netcdf\n",
    "7. Dump do arquivo para verificação\n",
    "8. Verificação do padrão CF\n",
    "\n",
    "Após desenvolvimento é possível exportar o codigo para .py e utilizar o codigo diretamente na linha de comando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega bibliotecas de acordo com o necessario\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "\n",
    "from netCDF4 import Dataset,num2date, date2num\n",
    "from datetime import timezone, timedelta\n",
    "\n",
    "from netCDF4 import Dataset,num2date, date2num, stringtoarr\n",
    "import json\n",
    "\n",
    "from gbdhidro import utilconversor\n",
    "from gbdhidro import utilcf\n",
    "from gbdhidro.netcdfjson import NetCDFJSON\n",
    "import base64\n",
    "\n",
    "import argparse\n",
    "\n",
    "from io import BytesIO\n",
    "import logging\n",
    "\n",
    "# Inicia logging\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Jupyter detectado. Alterando modo de operacao para DEBUG\n"
     ]
    }
   ],
   "source": [
    "# Verifica se esta no jupyter. Isso altera o comportamento do codigo\n",
    "IN_JUPYTER = utilconversor.isnotebook()\n",
    "if IN_JUPYTER:\n",
    "    DEBUG = True\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "    logger.info(\"Jupyter detectado. Alterando modo de operacao para DEBUG\")\n",
    "    # dentro do jupyter nao funciona o __FILE__. Então pegamos o diretorio atual\n",
    "    # que funciona corretamente no contexto do jupyter, mas não fora\n",
    "    here = os.getcwd()\n",
    "else:\n",
    "    DEBUG = False\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    # Pega path absoluto para esse arquivo\n",
    "    here = os.path.abspath(os.path.dirname(__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "if IN_JUPYTER:\n",
    "    from PIL import Image\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo de erro utilizado no shell em caso de problema\n",
    "ERROR_CODE = 1\n",
    "\n",
    "if not IN_JUPYTER:\n",
    "    parser = argparse.ArgumentParser(description='Converte arquivo para netCDF.')\n",
    "    parser.add_argument(\"-i\", \"--input\", help=\"nome do arquivo de entrada\")\n",
    "    parser.add_argument(\"-j\", \"--json\", help=\"nome do arquivo de configuracao json\")\n",
    "    parser.add_argument(\"-o\", \"--output\", help=\"nome do arquivo de saida. Se nao for informado eh gerado automaticamente\")\n",
    "    parser.add_argument(\"-d\", \"--directory\", help=\"nome do diretorio de saida\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    OUTPUT_FOLDER = args.directory\n",
    "    OUTPUT_FILE = args.output\n",
    "    FILE_PATH = args.input\n",
    "    JSON_FILE = args.json\n",
    "    \n",
    "    if FILE_PATH is None:\n",
    "        parser.print_help()\n",
    "        exit(ERROR_CODE)\n",
    "        \n",
    "    # TODO: encontrar uma forma para carreagr o arquivo automatico\n",
    "    #if JSON_FILE is None:\n",
    "    #    parser.print_help()\n",
    "    #    exit(ERROR_CODE)\n",
    "\n",
    "else:\n",
    "    # esta dentro do jupyter, utiliza valores padroes para debug\n",
    "    FILE_PATH = '../../input/h01.txt'\n",
    "    OUTPUT_FOLDER = '../../output'\n",
    "    OUTPUT_FILE = None\n",
    "    JSON_FILE = './h01.json'\n",
    "    \n",
    "# Arquivo com configuracao da estacao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre arquivo json de configuração\n",
    "with open(JSON_FILE, 'r') as fp:\n",
    "    json_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'h01',\n",
       " 'latitude': -31.3726,\n",
       " 'longitude': -52.6283,\n",
       " 'altitude': 404.0,\n",
       " 'image': 'h01.jpg',\n",
       " 'name_match_string': ['E102 02 2012A'],\n",
       " 'input_file_encoding': 'iso-8859-1'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if IN_JUPYTER:\n",
    "    display(json_data['station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome do arquivo de dados\n",
    "STATION_NAME = json_data['station']['name']\n",
    "# String com identificador utilizado para certificar que eh\n",
    "# o arquivo da estao escolhida\n",
    "STATION_NAME_MATCH = json_data['station']['name_match_string']\n",
    "LATITUDE = json_data['station']['latitude']\n",
    "LONGITUDE = json_data['station']['longitude']\n",
    "ALTITUDE = json_data['station']['altitude']\n",
    "IMAGE_FILE = json_data['station']['image']\n",
    "#DATETIME_MATCH = json_data['station']['datetime_match_string']\n",
    "#PRECIPITATION_MATCH = json_data['station']['precipitation_match_string']\n",
    "\n",
    "# Seleciona encoding do arquivo\n",
    "ENCODING = json_data['station']['input_file_encoding']\n",
    "DECIMAL = ','\n",
    "SEPARATOR = '\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Conversao para estacao h01\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Conversao para estacao {}\".format(STATION_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le arquivo de imagem\n",
    "with open(IMAGE_FILE, \"rb\") as image_file:\n",
    "    image_base64 = utilcf.bin2base64(image_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le somente o cabecalho para ver se eh o arquivo procurado\n",
    "fo = open(FILE_PATH, \"r\", encoding=ENCODING)\n",
    "first_line = fo.readline()\n",
    "second_line = fo.readline()\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processando estacao h01\n"
     ]
    }
   ],
   "source": [
    "# Verifica se tem numero de serie correto\n",
    "# Procura por alguns termos especifcos para verificar se o arquivo\n",
    "# esta dentro do esperado\n",
    "if utilconversor.find_matches(second_line,STATION_NAME_MATCH):\n",
    "    logger.info('Processando estacao ' + STATION_NAME)\n",
    "else:\n",
    "    logger.info(\"Erro: não é arquivo da estacao \" + STATION_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Time', 'Precipitação', 'Sedimentos', 'Nível', 'Vazão', 'Bateria']\n"
     ]
    }
   ],
   "source": [
    "# Le cabecalho da tabela\n",
    "# Estou abrindo e fechando o arquivo pq fica mais facil gerenciar. Não é o mais eficiente\n",
    "fo = open(FILE_PATH, \"r\", encoding=ENCODING)\n",
    "# pula as primeiras 14 linhas\n",
    "for i in range(14):\n",
    "    fo.readline()\n",
    "first_line = fo.readline()\n",
    "fo.readline()\n",
    "second_line = fo.readline()\n",
    "\n",
    "first_line_sep = first_line.split()\n",
    "second_line_sep = second_line.split()\n",
    "\n",
    "header = ['Date', 'Time'] + first_line_sep\n",
    "#for l1, l2 in zip(first_line_sep, second_line_sep):\n",
    "#    header.append(\"{} {}\".format(l1.strip(),l2.strip()))\n",
    "\n",
    "fo.close()\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Precipitação</th>\n",
       "      <th>Sedimentos</th>\n",
       "      <th>Nível</th>\n",
       "      <th>Vazão</th>\n",
       "      <th>Bateria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>10:00:20</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>95,003</td>\n",
       "      <td>201,870</td>\n",
       "      <td>13.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>10:10:20</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>95,003</td>\n",
       "      <td>201,870</td>\n",
       "      <td>13.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>10:20:20</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>95,003</td>\n",
       "      <td>201,870</td>\n",
       "      <td>13.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>10:30:20</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>95,003</td>\n",
       "      <td>201,870</td>\n",
       "      <td>13.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>10:40:20</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>87,643</td>\n",
       "      <td>178,194</td>\n",
       "      <td>12.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3766</td>\n",
       "      <td>Reinício</td>\n",
       "      <td>de</td>\n",
       "      <td>medidas</td>\n",
       "      <td>em</td>\n",
       "      <td>30/03/2020</td>\n",
       "      <td>11:25:06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3767</td>\n",
       "      <td>30/03/2020</td>\n",
       "      <td>11:25:06</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>95,003</td>\n",
       "      <td>178,194</td>\n",
       "      <td>13.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3768</td>\n",
       "      <td>Medidas</td>\n",
       "      <td>efetuadas</td>\n",
       "      <td>até</td>\n",
       "      <td>30/03/2020</td>\n",
       "      <td>11:25:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3769</td>\n",
       "      <td>Reinício</td>\n",
       "      <td>de</td>\n",
       "      <td>medidas</td>\n",
       "      <td>em</td>\n",
       "      <td>30/03/2020</td>\n",
       "      <td>11:25:24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3770</td>\n",
       "      <td>30/03/2020</td>\n",
       "      <td>11:25:24</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>95,003</td>\n",
       "      <td>178,194</td>\n",
       "      <td>13.115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3771 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Time Precipitação  Sedimentos       Nível     Vazão  \\\n",
       "0     04/03/2020   10:00:20        0,000       0,000      95,003   201,870   \n",
       "1     04/03/2020   10:10:20        0,000       0,000      95,003   201,870   \n",
       "2     04/03/2020   10:20:20        0,000       0,000      95,003   201,870   \n",
       "3     04/03/2020   10:30:20        0,000       0,000      95,003   201,870   \n",
       "4     04/03/2020   10:40:20        0,000       0,000      87,643   178,194   \n",
       "...          ...        ...          ...         ...         ...       ...   \n",
       "3766    Reinício         de      medidas          em  30/03/2020  11:25:06   \n",
       "3767  30/03/2020   11:25:06        0,000       0,000      95,003   178,194   \n",
       "3768     Medidas  efetuadas          até  30/03/2020    11:25:06       NaN   \n",
       "3769    Reinício         de      medidas          em  30/03/2020  11:25:24   \n",
       "3770  30/03/2020   11:25:24        0,000       0,000      95,003   178,194   \n",
       "\n",
       "      Bateria  \n",
       "0      13.226  \n",
       "1      13.352  \n",
       "2      13.278  \n",
       "3      13.278  \n",
       "4      12.947  \n",
       "...       ...  \n",
       "3766      NaN  \n",
       "3767   13.110  \n",
       "3768      NaN  \n",
       "3769      NaN  \n",
       "3770   13.115  \n",
       "\n",
       "[3771 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extrai dados da aquisicao\n",
    "table = pd.read_csv(FILE_PATH, delim_whitespace=True, skiprows=18, verbose=False, na_filter=True, header=None, encoding=ENCODING, decimal=DECIMAL, warn_bad_lines=True)\n",
    "\n",
    "table.columns = header\n",
    "\n",
    "if IN_JUPYTER:\n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procura por colunas de dados e gera erro se não encontrar  \n",
    "#'Precipitação', 'Sedimentos', 'Nível', 'Vazão', 'Bateria']\n",
    "var_list = {\n",
    "        'date': {'match':['Date'], 'pandas_col': None},\n",
    "        'time': {'match':['Time'], 'pandas_col': None},\n",
    "        'precipitation': {'netcdf_var':'precipitation', 'match':['Precipitação'], 'pandas_col': None},\n",
    "        'sediments': {'netcdf_var':'sediments', 'match':['Sedimentos'], 'pandas_col': None},\n",
    "        'level': {'netcdf_var':'level', 'match':['Nível'], 'pandas_col': None},\n",
    "        'battery': {'netcdf_var':'battery', 'match':['Bateria'], 'pandas_col': None}\n",
    "    }\n",
    "\n",
    "\n",
    "for key, value in var_list.items():\n",
    "    found = False\n",
    "    for column in table.columns:\n",
    "        if utilconversor.find_matches(column,value['match']):\n",
    "            value['pandas_col'] = column\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        logger.error('Erro, nao foi encontrada coluna {}'.format(key))\n",
    "        exit(ERROR_CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Precipitação</th>\n",
       "      <th>Sedimentos</th>\n",
       "      <th>Nível</th>\n",
       "      <th>Vazão</th>\n",
       "      <th>Bateria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>10:00:20</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>95,003</td>\n",
       "      <td>201,870</td>\n",
       "      <td>13.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>10:30:20</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>95,003</td>\n",
       "      <td>201,870</td>\n",
       "      <td>13.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>10:40:20</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>87,643</td>\n",
       "      <td>178,194</td>\n",
       "      <td>12.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>10:50:20</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>87,643</td>\n",
       "      <td>201,870</td>\n",
       "      <td>13.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>11:20:20</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>95,003</td>\n",
       "      <td>201,870</td>\n",
       "      <td>13.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3762</td>\n",
       "      <td>30/03/2020</td>\n",
       "      <td>11:00:57</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>87,643</td>\n",
       "      <td>178,194</td>\n",
       "      <td>13.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3763</td>\n",
       "      <td>30/03/2020</td>\n",
       "      <td>11:10:57</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>87,643</td>\n",
       "      <td>178,194</td>\n",
       "      <td>13.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3764</td>\n",
       "      <td>30/03/2020</td>\n",
       "      <td>11:20:57</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>87,643</td>\n",
       "      <td>178,194</td>\n",
       "      <td>13.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3767</td>\n",
       "      <td>30/03/2020</td>\n",
       "      <td>11:25:06</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>95,003</td>\n",
       "      <td>178,194</td>\n",
       "      <td>13.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3770</td>\n",
       "      <td>30/03/2020</td>\n",
       "      <td>11:25:24</td>\n",
       "      <td>0,000</td>\n",
       "      <td>0,000</td>\n",
       "      <td>95,003</td>\n",
       "      <td>178,194</td>\n",
       "      <td>13.115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3751 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date      Time Precipitação Sedimentos   Nível    Vazão  Bateria\n",
       "0     04/03/2020  10:00:20        0,000      0,000  95,003  201,870   13.226\n",
       "3     04/03/2020  10:30:20        0,000      0,000  95,003  201,870   13.278\n",
       "4     04/03/2020  10:40:20        0,000      0,000  87,643  178,194   12.947\n",
       "5     04/03/2020  10:50:20        0,000      0,000  87,643  201,870   13.262\n",
       "8     04/03/2020  11:20:20        0,000      0,000  95,003  201,870   13.331\n",
       "...          ...       ...          ...        ...     ...      ...      ...\n",
       "3762  30/03/2020  11:00:57        0,000      0,000  87,643  178,194   13.136\n",
       "3763  30/03/2020  11:10:57        0,000      0,000  87,643  178,194   13.115\n",
       "3764  30/03/2020  11:20:57        0,000      0,000  87,643  178,194   13.115\n",
       "3767  30/03/2020  11:25:06        0,000      0,000  95,003  178,194   13.110\n",
       "3770  30/03/2020  11:25:24        0,000      0,000  95,003  178,194   13.115\n",
       "\n",
       "[3751 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtra linhas incorretas\n",
    "bad_rows = []\n",
    "for index, row in table.iterrows():\n",
    "    date = row[var_list[\"date\"][\"pandas_col\"]]\n",
    "    time = row[var_list[\"time\"][\"pandas_col\"]]\n",
    "    # Apaga estes elementos da lista pois ja foram utilizados\n",
    "    # evita atrapalhar algm codigo mais adiante\n",
    "    #del var_list['date']\n",
    "    #del var_list['time']\n",
    "\n",
    "    date_str = '{} {}'.format(date, time)\n",
    "    try:\n",
    "        date_time = pd.to_datetime(date_str, format='%d/%m/%Y %H:%M:%S')\n",
    "    except:\n",
    "        bad_rows.append(index)\n",
    "\n",
    "if bad_rows:\n",
    "    table = table.drop(bad_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2020-03-04 10:00:20\n",
       "3      2020-03-04 10:30:20\n",
       "4      2020-03-04 10:40:20\n",
       "5      2020-03-04 10:50:20\n",
       "8      2020-03-04 11:20:20\n",
       "               ...        \n",
       "3762   2020-03-30 11:00:57\n",
       "3763   2020-03-30 11:10:57\n",
       "3764   2020-03-30 11:20:57\n",
       "3767   2020-03-30 11:25:06\n",
       "3770   2020-03-30 11:25:24\n",
       "Name: Date, Length: 3751, dtype: datetime64[ns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "date = table[var_list[\"date\"][\"pandas_col\"]]\n",
    "time = table[var_list[\"time\"][\"pandas_col\"]]\n",
    "# Apaga estes elementos da lista pois ja foram utilizados\n",
    "# evita atrapalhar algm codigo mais adiante\n",
    "del var_list['date']\n",
    "del var_list['time']\n",
    "\n",
    "date_str = date.str.cat(time, sep=\" \")\n",
    "date_time = pd.to_datetime(date_str, format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "if IN_JUPYTER:\n",
    "    display(date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Inicio e fim de medidas em UTC: 20200304T100020Z - 20200330T112524Z\n"
     ]
    }
   ],
   "source": [
    "# Processa datetime para incluir timezone\n",
    "#date_str = table[date_time_col]\n",
    "#date_time = pd.to_datetime(date_str, format='%d/%m/%y %I:%M:%S %p')\n",
    "# extrai informacao de gmt\n",
    "#gmt_hour_offset, gmt_minute_offset = utilconversor.get_gmt_offset(date_time.name)\n",
    "# TODO: Como converte para UTC essa estacao?\n",
    "gmt_hour_offset = 0\n",
    "gmt_minute_offset = 0\n",
    "tzinfo=timezone(timedelta(hours=gmt_hour_offset, minutes=gmt_minute_offset))\n",
    "# gera os indices com informacao de fuso horarios incluido\n",
    "index = date_time.dt.tz_localize(tzinfo)\n",
    "# converte para UTC\n",
    "index_utc = index.dt.tz_convert('UTC')\n",
    "first_day_str = utilcf.datetime2str(index_utc.iloc[0])\n",
    "last_day_str = utilcf.datetime2str(index_utc.iloc[-1])\n",
    "logger.info(\"Inicio e fim de medidas em UTC: {} - {}\".format(first_day_str, last_day_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontra coluna com chuva\n",
    "#precipitation = table[cols['rain']['col']]\n",
    "\n",
    "#if IN_JUPYTER:\n",
    "#    display(precipitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Nome de arquivo de saida: h01_20200304T100020Z_20200330T112524Z.nc\n"
     ]
    }
   ],
   "source": [
    "# Gera nome de arquivo de saida\n",
    "#file_name = '{}_{}_{}.nc'.format(STATION_NAME, first_day_str, last_day_str)\n",
    "#logger.info(\"Nome de arquivo de saida: {}\".format(file_name))\n",
    "\n",
    "if OUTPUT_FILE is None:\n",
    "    file_name = '{}_{}_{}.nc'.format(STATION_NAME, first_day_str, last_day_str)\n",
    "else:\n",
    "    file_name = OUTPUT_FILE\n",
    "\n",
    "if OUTPUT_FOLDER is None:\n",
    "    nc_file_path = file_name\n",
    "else:\n",
    "    nc_file_path = os.path.join(OUTPUT_FOLDER, file_name)\n",
    "\n",
    "logger.info(\"Nome de arquivo de saida: {}\".format(file_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geracao de arquivo netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nc_file_path = os.path.join(OUTPUT_FOLDER, file_name)\n",
    "# Cria arquivo netCDF\n",
    "nc_file = NetCDFJSON()\n",
    "nc_file.write(nc_file_path)\n",
    "# Le arquivo json com configuracao da estrutura do netcdf\n",
    "nc_file.load_json(JSON_FILE)\n",
    "nc_file.create_from_json()\n",
    "\n",
    "# pega handlers para dimensoes\n",
    "timeDim = nc_file.get_dimension('time')\n",
    "nameDim = nc_file.get_dimension('name_strlen')\n",
    "# pega handlers para variaveis\n",
    "time = nc_file.get_variable('time')\n",
    "time_bnds = nc_file.get_variable('time_bnds')\n",
    "lat = nc_file.get_variable('lat')\n",
    "lon = nc_file.get_variable('lon')\n",
    "alt = nc_file.get_variable('alt')\n",
    "station_name = nc_file.get_variable('station_name')\n",
    "precip = nc_file.get_variable('precipitation')\n",
    "station_image = nc_file.get_variable('station_image')\n",
    "\n",
    "# Recupera qual o valor uilizado para valores que estao faltando\n",
    "#FILL_VALUE = precip._FillValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insere lista de variaveis no netcdf\n",
    "for key, value in var_list.items():\n",
    "    nc_var = nc_file.get_variable(value['netcdf_var'])\n",
    "    FILL_VALUE = nc_var._FillValue\n",
    "    data_var = table[value['pandas_col']]\n",
    "    data_var = data_var.replace(np.nan, FILL_VALUE)\n",
    "    data_var = data_var.to_numpy()\n",
    "    nc_var[:] = data_var\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitui Nan por FILL_VALUE\n",
    "#precipitation = precipitation.replace(np.nan, FILL_VALUE)\n",
    "\n",
    "# Seta variaveis\n",
    "nc_time = index_utc.to_numpy()\n",
    "nc_time = date2num(nc_time,units=time.units,calendar=time.calendar)\n",
    "# Como a precipitacao e o acumulado entre a ultima medida e a atual\n",
    "# é necessario informar isso atraves dos bounds de tempo, ou seja,\n",
    "# os valores inferioes e superiores respectivos ao limite do eixo de temp0\n",
    "# O bound superior e o mesmo que o horario da medids\n",
    "nc_superior_bound_time = nc_time\n",
    "# bound inferior e o horario da ultima medida\n",
    "nc_inferior_bound_time = np.roll(nc_superior_bound_time,1)\n",
    "# a primeira medida não tem medida anterior, por isso seta para o mesmo valor\n",
    "nc_inferior_bound_time[0] = nc_superior_bound_time[0]\n",
    "# combina bound inferior com bound superior\n",
    "bnds = np.stack((nc_inferior_bound_time, nc_superior_bound_time), axis=-1)\n",
    "\n",
    "#nc_serie = precipitation.to_numpy()\n",
    "\n",
    "nc_station_name = STATION_NAME\n",
    "latitude = LATITUDE\n",
    "longitude = LONGITUDE\n",
    "altitude = ALTITUDE\n",
    "\n",
    "lat[:] = np.array([latitude])\n",
    "lon[:] = np.array([longitude])\n",
    "alt[:] = np.array([altitude])\n",
    "\n",
    "time[:] = nc_time\n",
    "time_bnds[:] = bnds\n",
    "\n",
    "#precip[:] = np.array(nc_serie)\n",
    "\n",
    "station_name[:] = stringtoarr(nc_station_name, nameDim.size)\n",
    "station_image[:] = stringtoarr(image_base64, len(image_base64))\n",
    "station_image.file_name = IMAGE_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz processamento para metadados\n",
    "# Processa os dados ja convertidos para facilitar reutilizar o codigo depois\n",
    "\n",
    "# min max lat e lon\n",
    "min_lat = np.amin(lat)\n",
    "max_lat = np.amax(lat)\n",
    "min_lon = np.amin(lon)\n",
    "max_lon = np.amax(lon)\n",
    "\n",
    "# time duration\n",
    "min_time = num2date(np.amin(time), units=time.units, calendar=time.calendar)\n",
    "max_time = num2date(np.amax(time), units=time.units, calendar=time.calendar)\n",
    "min_time_str = utilcf.datetime2str(min_time)\n",
    "max_time_str = utilcf.datetime2str(max_time)\n",
    "time_delta = max_time - min_time\n",
    "time_delta_str = utilcf.timedelta2str(time_delta)\n",
    "\n",
    "# time resolution\n",
    "time1 = num2date(time[1], units=time.units, calendar=time.calendar)\n",
    "time0 = num2date(time[0], units=time.units, calendar=time.calendar)\n",
    "time_resolution = time1 - time0\n",
    "time_resolution_str = utilcf.timedelta2str(time_resolution)\n",
    "\n",
    "\n",
    "logger.info('Min/Max latitude: {}/{}'.format(min_lat,max_lat))\n",
    "logger.info('Min/Max longitude: {}/{}'.format(min_lon,max_lon))\n",
    "logger.info('Min/Max datetime: {}/{}'.format(min_time_str,max_time_str))\n",
    "logger.info('Time duration:{}'.format(time_delta_str))\n",
    "logger.info('Time resolution:{}'.format(time_resolution_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualiza metadados\n",
    "nc_file.rootgrp.geospatial_lat_min = min_lat\n",
    "nc_file.rootgrp.geospatial_lat_max = max_lat\n",
    "nc_file.rootgrp.geospatial_lon_min = min_lon\n",
    "nc_file.rootgrp.geospatial_lon_max = max_lon\n",
    "nc_file.rootgrp.time_coverage_start = min_time_str\n",
    "nc_file.rootgrp.time_coverage_end = max_time_str\n",
    "nc_file.rootgrp.time_coverage_duration = time_delta_str\n",
    "nc_file.rootgrp.time_coverage_resolution = time_resolution_str\n",
    "nc_file.rootgrp.id = file_name\n",
    "nc_file.rootgrp.date_created = utilcf.datetime2str(datetime.now(timezone.utc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nc_file.rootgrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza dados para confirma se esta tudo ok.\n",
    "# Date time deve ser linear, sem quebras abruptas\n",
    "if IN_JUPYTER:\n",
    "    fig, (ax0, ax1) = plt.subplots(ncols=2)\n",
    "    ax0.plot(time[:])\n",
    "    ax0.set_title('Date time')\n",
    "    ax1.plot(precip[:])\n",
    "    ax1.set_title('Variavel')\n",
    "    plt.show() \n",
    "\n",
    "    # Mostra imagem\n",
    "    image = utilcf.base642bin(station_image[:])\n",
    "    print(station_image.file_name)\n",
    "    im = Image.open(image)\n",
    "    display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fecha e salva arquivo\n",
    "nc_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump do arquivo nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta o dump do arquivo netcdf\n",
    "# Precisa instalar: sudo apt install netcdf-bin \n",
    "if IN_JUPYTER:\n",
    "    cmd = '\"' + nc_file_path + '\"'\n",
    "    !ncdump {  cmd }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifica se arquivo .nc atende o CF Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica compatibilidade com CF\n",
    "# Precisa instalar pip install cfchecker \n",
    "# site: https://pypi.org/project/cfchecker/\n",
    "if IN_JUPYTER:\n",
    "    CF_VERSION = '1.7'\n",
    "    cmd = '-v ' + CF_VERSION + ' ' + '\"' + nc_file_path + '\"'\n",
    "    !cfchecks {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
